ML_Assignment_2_EDA_and_Preprocessing
import pandas as pd

# Load the dataset
url = 'https://drive.google.com/uc?export=download&id=1F3lRf32JM8ejnXq-Cbf9y7fa57zSHGz_'
df = pd.read_csv(url)

# 1. List down the unique values in each feature
unique_values = {col: df[col].unique() for col in df.columns}
print("Unique Values in Each Column:")
print(unique_values)

# 2. Find the length of the dataset
print(f"Length of the dataset: {len(df)}")

# 3. Perform statistical analysis
print("\nStatistical Summary of the Dataset:")
print(df.describe())

# 4. Rename the columns (If needed, based on the dataset structure)
df.rename(columns={'OldColumnName': 'NewColumnName'}, inplace=True)  # Example, rename if needed

# View the first few rows of the dataset
print("\nFirst few rows of the dataset:")
print(df.head())

import numpy as np

# 1. Find the missing values in each column
missing_values = df.isnull().sum()
print("\nMissing Values in Each Column:")
print(missing_values)

# 2. Replace 0 values in the 'age' column with NaN
df['age'] = df['age'].replace(0, np.nan)

# 3. Handle missing values
# For numerical columns, replace NaN with the mean of the column
df['age'].fillna(df['age'].mean(), inplace=True)  # Replace NaN in 'age' with mean
df['salary'].fillna(df['salary'].median(), inplace=True)  # Replace NaN in 'salary' with median

# For categorical columns, replace NaN with the mode (most frequent value)
df['place'].fillna(df['place'].mode()[0], inplace=True)

# 4. Remove duplicate rows
df.drop_duplicates(inplace=True)

# 5. Find and handle outliers (example using Z-score)
from scipy import stats

z_scores = stats.zscore(df[['age', 'salary']])
df_no_outliers = df[(np.abs(z_scores) < 3).all(axis=1)]  # Keeping only rows where Z-score is less than 3

print("\nData after Cleaning:")
print(df_no_outliers.head())

import matplotlib.pyplot as plt
import seaborn as sns

# 1. Filter the data based on age > 40 and salary < 5000
filtered_data = df_no_outliers[(df_no_outliers['age'] > 40) & (df_no_outliers['salary'] < 5000)]
print("\nFiltered Data (Age > 40 and Salary < 5000):")
print(filtered_data.head())

# 2. Plot the relationship between age and salary
plt.figure(figsize=(8, 6))
sns.scatterplot(x=filtered_data['age'], y=filtered_data['salary'])
plt.title('Age vs Salary (Filtered)')
plt.xlabel('Age')
plt.ylabel('Salary')
plt.show()

# 3. Count the number of people from each place and represent it visually
place_counts = df_no_outliers['place'].value_counts()
plt.figure(figsize=(8, 6))
sns.barplot(x=place_counts.index, y=place_counts.values)
plt.title('Count of People from Each Place')
plt.xlabel('Place')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()


from sklearn.preprocessing import LabelEncoder

# 1. One-Hot Encoding for categorical variables like 'place'
df_encoded = pd.get_dummies(df_no_outliers, columns=['place'], drop_first=True)

# 2. Label Encoding for a categorical variable if needed (e.g., gender)
le = LabelEncoder()
df_encoded['gender'] = le.fit_transform(df_encoded['gender'])

print("\nData After Encoding:")
print(df_encoded.head())


from sklearn.preprocessing import StandardScaler, MinMaxScaler

# 1. Standard Scaling
scaler_standard = StandardScaler()
df_encoded[['age', 'salary']] = scaler_standard.fit_transform(df_encoded[['age', 'salary']])

# 2. MinMax Scaling
scaler_minmax = MinMaxScaler()
df_encoded[['age', 'salary']] = scaler_minmax.fit_transform(df_encoded[['age', 'salary']])

print("\nData After Scaling:")
print(df_encoded.head())


